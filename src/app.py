import streamlit as st
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from gensim.models import Word2Vec
from data import unified_text_processor, get_final_df
import warnings
warnings.filterwarnings('ignore')

# Fonction pour traiter un seul texte
def process_user_input(user_input):
    # Cr√©er un DataFrame temporaire avec la m√™me structure que vos donn√©es d'entra√Ænement
    temp_df = pd.DataFrame({
        'text': [user_input],
        'title': [''],
        'subject': [''],
        'date': [''],
        'label': [None]  # None car c'est une pr√©diction
    })
    
    # Appliquer le traitement NLP
    processed_df = unified_text_processor(temp_df)
    return processed_df

# Charger les mod√®les
@st.cache_resource
def load_models():
    # Charger le mod√®le LSTM
    lstm_model = load_model("trained_models/lstm_model.keras")
    
    # Charger le mod√®le Word2Vec
    w2v_model = Word2Vec.load("models/w2v_fake_news.model")
    
    return lstm_model, w2v_model

# Interface Streamlit
st.title("üïµÔ∏è‚Äç‚ôÇÔ∏è Fake News Detector")
st.write("Entrez un article de news pour v√©rifier son authenticit√©")

# Zone de texte
user_input = st.text_area("Coller le texte de l'article ici:", height=200)

if st.button("Analyser"):
    if user_input:
        try:
            # Charger les mod√®les
            model, w2v_model = load_models()
            
            # 1. Pr√©traiter le texte
            processed_df = process_user_input(user_input)
            
            # 2. Cr√©er l'embedding Word2Vec (identique √† votre pipeline d'entra√Ænement)
            def document_vector(tokens):
                words = [word for word in tokens if word in w2v_model.wv]
                return np.mean(w2v_model.wv[words], axis=0) if words else np.zeros(w2v_model.vector_size)
            
            embedding = document_vector(processed_df.iloc[0]['tokens'])
            embedding = np.array([embedding])  # Ajouter une dimension batch
            
            # 3. Faire la pr√©diction
            prediction = model.predict(embedding)
            proba = prediction[0][0]
            
            # 4. Afficher les r√©sultats
            st.subheader("R√©sultat")
            if proba < 0.5:  # Changement de > √† <
                st.error(f"‚ö†Ô∏è Fake News (confiance: {1-proba:.2%})")
            else:
                st.success(f"‚úÖ News Authentique (confiance: {proba:.2%})")
            
            # Jauge de confiance
            st.progress(float(proba if proba > 0.5 else 1-proba))
            
            # Analyse d√©taill√©e
            with st.expander("D√©tails de l'analyse"):
                st.write("**Statistiques du texte:**")
                st.json({
                    "Mots": processed_df.iloc[0]['word_count'],
                    "Noms": processed_df.iloc[0]['noun_count'],
                    "Sentiment": "Positif" if processed_df.iloc[0]['sentiment'] > 0 
                                else "N√©gatif" if processed_df.iloc[0]['sentiment'] < 0 
                                else "Neutre"
                })
                
        except Exception as e:
            st.error(f"Une erreur est survenue: {str(e)}")
    else:
        st.warning("Veuillez entrer un texte √† analyser")